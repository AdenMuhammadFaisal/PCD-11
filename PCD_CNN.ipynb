{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/Drive/')"
      ],
      "metadata": {
        "id": "F14uNIDqCCa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "path_to_zip_file = \"/content/Drive/MyDrive/Aden Muhammad Faisal/Salinan Praktikum Morfologi dan CNN.zip\"\n",
        "directory_to_extract_to = \"/content/Drive/MyDrive/Aden Muhammad Faisal/Classroom\"\n",
        "\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "  zip_ref.extractall(directory_to_extract_to)"
      ],
      "metadata": {
        "id": "uZBDa5YNDcJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XquwYHystm_"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan direktori utama dataset\n",
        "#dataset ini upload terlebih dulu ke drive agar bisa di load di google colab,\n",
        "#atau kalian bisa langsung download lewat kaggle langsung di google colab\n",
        "\n",
        "import os\n",
        "base_dir = '/content/Drive/MyDrive/Aden Muhammad Faisal/Classroom/Praktikum Morfologi dan CNN/LATIHAN CNN/flowers'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(base_dir))"
      ],
      "metadata": {
        "id": "ruHaHNHzs7Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghitung jumlah gambar pada dataset\n",
        "number_label = {}\n",
        "total_files = 0\n",
        "for i in os.listdir(base_dir):\n",
        "    counting = len(os.listdir(os.path.join(base_dir, i)))\n",
        "    number_label[i] = counting\n",
        "    total_files += counting\n",
        "\n",
        "print(\"Total Files : \" + str(total_files))"
      ],
      "metadata": {
        "id": "cSS3yq1mtDMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisasi jumlah gambar tiap kelas\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.bar(number_label.keys(), number_label.values());\n",
        "plt.title(\"Jumlah Gambar Tiap Label\");\n",
        "plt.xlabel('Label');\n",
        "plt.ylabel('Jumlah Gambar');"
      ],
      "metadata": {
        "id": "CiClR18etP1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan sampel gambar tiap kelas\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "img_each_class = 1\n",
        "img_samples = {}\n",
        "classes = list(number_label.keys())\n",
        "\n",
        "\n",
        "for c in classes:\n",
        "    temp = os.listdir(os.path.join(base_dir, c))[:img_each_class]\n",
        "    for item in temp:\n",
        "        img_path = os.path.join(base_dir, c, item)\n",
        "        img_samples[c] = img_path\n",
        "\n",
        "for i in img_samples:\n",
        "    fig = plt.gcf()\n",
        "    img = mpimg.imread(img_samples[i])\n",
        "    plt.title(i)\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vQV57ZkStUv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation"
      ],
      "metadata": {
        "id": "WdAdLkoluDvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = (200,200)\n",
        "BATCH_SIZE = 32\n",
        "SEED = 999"
      ],
      "metadata": {
        "id": "2ypuPEpqtabi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan ImageDataGenerator untuk preprocessing\n",
        "import tensorflow as tf\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "GHkHzOpjto6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyiapkan data train dan data validation\n",
        "train_data = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "valid_data = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed=SEED\n",
        ")"
      ],
      "metadata": {
        "id": "2Ufxd7CDtpz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Augmentation\n",
        "data_augmentation = tf.keras.Sequential(\n",
        "  [\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\",\n",
        "                      input_shape=(IMAGE_SIZE[0],\n",
        "                                  IMAGE_SIZE[1],\n",
        "                                  3)),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "    tf.keras.layers.Rescaling(1./255)\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "8XHkgfnutvha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelling\n",
        "\n",
        "Membuat Arsitektur CNN\n",
        "\n",
        "Penyusunan Layer"
      ],
      "metadata": {
        "id": "HCX2MwjTt6QR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat arsitektur model CNN\n",
        "cnn_model = tf.keras.models.Sequential([\n",
        "  data_augmentation,\n",
        "  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Dropout(0.3),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compiling model\n",
        "cnn_model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        "  )"
      ],
      "metadata": {
        "id": "EjUrwsVbtzwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melatih model CNN"
      ],
      "metadata": {
        "id": "NUkLvUgjuP2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training model CNN\n",
        "cnn_hist = cnn_model.fit(\n",
        "    train_data,\n",
        "    epochs=20,\n",
        "    validation_data = valid_data\n",
        ")"
      ],
      "metadata": {
        "id": "fnGexRMXuJhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluasi Model CNN"
      ],
      "metadata": {
        "id": "5yoHEi01uZUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat plot akurasi model CNN\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(cnn_hist.history['accuracy'])\n",
        "plt.plot(cnn_hist.history['val_accuracy'])\n",
        "plt.title('CNN model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "# Membuat plot loss model CNN\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(cnn_hist.history['loss'])\n",
        "plt.plot(cnn_hist.history['val_loss'])\n",
        "plt.title('CNN model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TAsGKi7guZ4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer Learning Menggunakan VGG16\n",
        "\n",
        "Memuat Model VGG16"
      ],
      "metadata": {
        "id": "X9-n-q9KufXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "## Loading VGG16 model\n",
        "base_vgg_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "base_vgg_model.trainable = False\n",
        "\n",
        "# Preprocessing Input\n",
        "vgg_preprocess = tf.keras.applications.vgg16.preprocess_input\n",
        "train_data.preprocessing_function = vgg_preprocess"
      ],
      "metadata": {
        "id": "Z6-dTfJXuk1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer learning dengan VGG16\n",
        "vgg_model = tf.keras.models.Sequential([\n",
        "  data_augmentation,\n",
        "  base_vgg_model,\n",
        "  tf.keras.layers.Dropout(0.7),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compiling model\n",
        "vgg_model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        "  )"
      ],
      "metadata": {
        "id": "Jz3-Wx3MuqFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melatih Model"
      ],
      "metadata": {
        "id": "rv-rLnsau0cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model VGG16\n",
        "vgg_hist = vgg_model.fit(\n",
        "    train_data,\n",
        "    epochs=20,\n",
        "    validation_data = valid_data\n",
        ")"
      ],
      "metadata": {
        "id": "AZAkjNi8u0-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluasi Model"
      ],
      "metadata": {
        "id": "_rsqxoxOu4q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat plot akurasi model VGG16\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(vgg_hist.history['accuracy'])\n",
        "plt.plot(vgg_hist.history['val_accuracy'])\n",
        "plt.title('VGG16 model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "# Membuat plot loss model VGG16\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(vgg_hist.history['loss'])\n",
        "plt.plot(vgg_hist.history['val_loss'])\n",
        "plt.title('VGG16 model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a85-EpMgu-gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer Learning Menggunakan ResNet50\n",
        "\n",
        "Memuat Model ResNet50"
      ],
      "metadata": {
        "id": "bbOS13fTvEC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Loading ResNet50 model\n",
        "base_resnet_model = ResNet50(include_top=False,\n",
        "                   input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3),\n",
        "                   pooling='max',classes=5,\n",
        "                   weights='imagenet')\n",
        "\n",
        "base_resnet_model.trainable = False\n",
        "\n",
        "train_data.preprocessing_function = tf.keras.applications.resnet50.preprocess_input\n",
        "\n",
        "\n",
        "# Transfer learning ResNet50\n",
        "resnet_model = tf.keras.models.Sequential([\n",
        "    data_augmentation,\n",
        "    base_resnet_model,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(5, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "Ta_0z3vYvJAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling model\n",
        "resnet_model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        "  )"
      ],
      "metadata": {
        "id": "umB-Y7W1vM5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melatih Model"
      ],
      "metadata": {
        "id": "d83kIEJavRnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model ResNet50\n",
        "resnet_hist = resnet_model.fit(\n",
        "    train_data,\n",
        "    epochs=20,\n",
        "    validation_data = valid_data\n",
        ")"
      ],
      "metadata": {
        "id": "yYHOIf1cvVmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluasi Model"
      ],
      "metadata": {
        "id": "D_K2fZL4vaFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat plot akurasi model ResNet50\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(resnet_hist.history['accuracy'])\n",
        "plt.plot(resnet_hist.history['val_accuracy'])\n",
        "plt.title('ResNet50 model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "# Membuat plot loss model ResNet50\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(resnet_hist.history['loss'])\n",
        "plt.plot(resnet_hist.history['val_loss'])\n",
        "plt.title('ResNet50 model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BWgNoM5BvdlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer Learning Menggunakan DenseNet201\n",
        "\n",
        "Memuat Model DenseNet201"
      ],
      "metadata": {
        "id": "w6J5D7UTvjHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading DenseNet201 model\n",
        "base_densenet_model = tf.keras.applications.DenseNet201(include_top=False,\n",
        "                                                        weights='imagenet',\n",
        "                                                        input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),\n",
        "                                                        pooling='max')\n",
        "base_densenet_model.trainable=False\n",
        "train_data.preprocessing_function = tf.keras.applications.densenet.preprocess_input"
      ],
      "metadata": {
        "id": "pLlyUyUxvnMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer learning DenseNet201\n",
        "densenet_model = tf.keras.models.Sequential([\n",
        "  data_augmentation,\n",
        "  base_densenet_model,\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compiling model\n",
        "densenet_model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        "  )"
      ],
      "metadata": {
        "id": "5EdowzHgvtAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melatih Model"
      ],
      "metadata": {
        "id": "xDUTPeQ_v0sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model DenseNet201\n",
        "densenet_hist = densenet_model.fit(\n",
        "    train_data,\n",
        "    epochs=20,\n",
        "    validation_data = valid_data\n",
        ")"
      ],
      "metadata": {
        "id": "_vrTfjFfv5Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluasi Model"
      ],
      "metadata": {
        "id": "ZK3vTdutv9ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat plot akurasi model DenseNet201\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(densenet_hist.history['accuracy'])\n",
        "plt.plot(densenet_hist.history['val_accuracy'])\n",
        "plt.title('DenseNet201 model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "# Membuat plot loss model DenseNet201\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(densenet_hist.history['loss'])\n",
        "plt.plot(densenet_hist.history['val_loss'])\n",
        "plt.title('DenseNet201 model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vP8w9_wFv-up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "5sAK_7qbwFqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat plot akurasi empat model sebelumnya untuk dibandingkan\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(cnn_hist.history['val_accuracy'])\n",
        "plt.plot(vgg_hist.history['val_accuracy'])\n",
        "plt.plot(resnet_hist.history['val_accuracy'])\n",
        "plt.plot(densenet_hist.history['val_accuracy'])\n",
        "plt.title('model validation accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['CNN', 'VGG16', 'ResNet50', 'DenseNet201'], loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_l8WaueCwJTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uji Coba Model"
      ],
      "metadata": {
        "id": "u8toRIdhwRNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan daftar kelas atau label gambar\n",
        "train_data.class_indices"
      ],
      "metadata": {
        "id": "U_5lYa-_wmAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menguji coba model\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from google.colab import files\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "#file upload, kode di bawah in hanya bisa dijalankan di google colab dengan mengimport from google.colab import files. Silahkan kalian ganti kodingannya agar bisa upload di jupyter notebook masing-masing\n",
        "#atau kalian langsung import file gambarnya langsung\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # prediksi gambar\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=IMAGE_SIZE)\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = densenet_model.predict(images, batch_size=BATCH_SIZE)\n",
        "  classes = np.argmax(classes)\n",
        "\n",
        "  print(fn)\n",
        "  if classes==0:\n",
        "    print('daisy')\n",
        "  elif classes==1:\n",
        "    print('dandelion')\n",
        "  elif classes==2:\n",
        "    print('rose')\n",
        "  elif classes==3:\n",
        "    print('sunflower')\n",
        "  else:\n",
        "    print('tulip')"
      ],
      "metadata": {
        "id": "2RZHxyWnwSTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment\n",
        "\n",
        "Agar nantinya dapat diimplementasikan atau dikembangkan lebih lanjut, model perlu dilakukan deploy terlebih dahulu dalam format HDF5, TFLite (Mobile) atau TensorflowJS (Web)\n",
        "\n",
        "HDF5"
      ],
      "metadata": {
        "id": "Nw8dLkSZwr0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "densenet_model.save('model-flowers-recognition.h5')"
      ],
      "metadata": {
        "id": "mcSXJ9dJww5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TFLite"
      ],
      "metadata": {
        "id": "ERje2Zvdw0e-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(densenet_model)\n",
        "tflite_model = converter.convert()\n",
        "with tf.io.gfile.GFile('model-flowers-recognition.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "6ma8RS6ew4Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorflowJS"
      ],
      "metadata": {
        "id": "9R9WI35-w7K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instal TensorflowJS\n",
        "!pip install tensorflowjs"
      ],
      "metadata": {
        "id": "vVKw5qaJw9zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorflowjs_converter \\\n",
        "    --input_format=keras \\\n",
        "    /content/model-flowers-recognition.h5 /content/modeltfjs"
      ],
      "metadata": {
        "id": "S0KDd5elxG9-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}